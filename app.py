import json
import re
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import requests
import streamlit as st
from openai import OpenAI  # pip install openai

# =========================
# Streamlit ì„¤ì •
# =========================
st.set_page_config(page_title="ğŸ¬ ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì˜í™”ëŠ”?", page_icon="ğŸ¬", layout="wide")
st.title("ğŸ¬ ë‚˜ì™€ ì–´ìš¸ë¦¬ëŠ” ì˜í™”ëŠ”?")
st.write(
    "ì§ˆë¬¸ 5ê°œë¡œ ì·¨í–¥ì„ ë¶„ì„í•˜ê³ , **TMDBì—ì„œ ì¥ë¥´ ì í•©ì„±ê³¼ ê°ê´€ì„±(í‰ì /íˆ¬í‘œìˆ˜/í•„í„°)**ì„ ê°•í™”í•´ ì¶”ì²œí•´ìš” ğŸ¿âœ¨\n"
    "ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ì—” **í›„ë³´ 5ê°œ ì¤‘ AIê°€ 1í¸ë§Œ ìµœì¢… í”½**í•´ì¤˜ìš” ğŸ¤–\n\n"
    "âœ… ë§ˆìŒì— ì•ˆ ë“œëŠ” ì˜í™”ê°€ ë‚˜ì˜¤ë©´, ì²´í¬í•´ì„œ **ì œì™¸ í›„ ë‹¤ì‹œ ì¶”ì²œ**í•  ìˆ˜ ìˆì–´ìš”!"
)

TMDB_BASE = "https://api.themoviedb.org/3"

# =========================
# ì¥ë¥´/ë¶„ì„ ì„¤ì •
# =========================
CATEGORY_TO_GENRE_IDS = {
    "ë¡œë§¨ìŠ¤/ë“œë¼ë§ˆ": [10749],  # ë¡œë§¨ìŠ¤ë§Œ
    "ì•¡ì…˜/ì–´ë“œë²¤ì²˜": [28],
    "SF/íŒíƒ€ì§€": [878, 14],
    "ì½”ë¯¸ë””": [35],
}

INDEX_TO_CATEGORY = {0: "ë¡œë§¨ìŠ¤/ë“œë¼ë§ˆ", 1: "ì•¡ì…˜/ì–´ë“œë²¤ì²˜", 2: "SF/íŒíƒ€ì§€", 3: "ì½”ë¯¸ë””"}

CATEGORY_BADGE = {"ë¡œë§¨ìŠ¤/ë“œë¼ë§ˆ": "ğŸ’•", "ì•¡ì…˜/ì–´ë“œë²¤ì²˜": "ğŸ’¥", "SF/íŒíƒ€ì§€": "ğŸš€", "ì½”ë¯¸ë””": "ğŸ˜‚"}

REASON_BY_CATEGORY = {
    "ë¡œë§¨ìŠ¤/ë“œë¼ë§ˆ": "ê´€ê³„/ê°ì •ì„ ì„ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ì„ íƒì´ ë§ì•„ì„œ, TMDB ê¸°ì¤€ **ë¡œë§¨ìŠ¤(10749)** ì˜í™”ë§Œ ì—„ê²©í•˜ê²Œ ê³¨ë¼ìš” ğŸ’•",
    "ì•¡ì…˜/ì–´ë“œë²¤ì²˜": "ìŠ¤ì¼€ì¼ê³¼ ì¶”ì§„ë ¥ì„ ì„ í˜¸í•˜ëŠ” ì„ íƒì´ ë§ì•„ì„œ, ì‹œì›í•œ ì „ê°œê°€ ìˆëŠ” **ì•¡ì…˜(28)** ì¤‘ì‹¬ìœ¼ë¡œ ê³¨ë¼ìš” ğŸ’¥",
    "SF/íŒíƒ€ì§€": "ìƒìƒë ¥/ì„¸ê³„ê´€ì„ ì¦ê¸°ëŠ” ì„ íƒì´ ë§ì•„ì„œ, **SF(878)/íŒíƒ€ì§€(14)** ì¤‘ì‹¬ìœ¼ë¡œ ê³¨ë¼ìš” ğŸš€",
    "ì½”ë¯¸ë””": "ê°€ë³ê²Œ ì¦ê¸°ê³  ì›ƒëŠ” í¬ì¸íŠ¸ë¥¼ ì¤‘ìš”í•˜ê²Œ ì—¬ê²¨ì„œ, **ì½”ë¯¸ë””(35)** ì¤‘ì‹¬ìœ¼ë¡œ ê³¨ë¼ìš” ğŸ˜‚",
}

SORT_OPTIONS = {
    "ì¸ê¸°ìˆœ (TMDB)": ("popularity.desc", False),
    "í‰ì  ë†’ì€ìˆœ (TMDB)": ("vote_average.desc", False),
    "ìµœì‹  ê°œë´‰ìˆœ (TMDB)": ("primary_release_date.desc", False),
    "íˆ¬í‘œìˆ˜ ë§ì€ìˆœ (TMDB)": ("vote_count.desc", False),
    "ê°œì¸ ì·¨í–¥ ê°€ì¤‘ì¹˜ (ë¡œì»¬ ì ìˆ˜)": (None, True),
}

# =========================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”(ì œì™¸ ëª©ë¡/ë§ˆì§€ë§‰ ì¶”ì²œ ìºì‹œ)
# =========================
if "excluded_movie_ids" not in st.session_state:
    st.session_state["excluded_movie_ids"] = set()
if "last_reco_context" not in st.session_state:
    st.session_state["last_reco_context"] = None  # ì¶”ì²œ ì¬ìƒì„±ì— í•„ìš”í•œ ì •ë³´ ì €ì¥
if "last_llm_candidates" not in st.session_state:
    st.session_state["last_llm_candidates"] = []
if "last_cfg" not in st.session_state:
    st.session_state["last_cfg"] = None
if "last_picked_id" not in st.session_state:
    st.session_state["last_picked_id"] = None
if "last_picked_md" not in st.session_state:
    st.session_state["last_picked_md"] = ""


# =========================
# ì‚¬ì´ë“œë°”: API í‚¤/ì˜µì…˜
# =========================
with st.sidebar:
    st.header("ğŸ”‘ API ì„¤ì •")
    tmdb_key = st.text_input("TMDB API Key", type="password", placeholder="TMDB API Key ì…ë ¥")
    openai_key = st.text_input("OpenAI API Key", type="password", placeholder="OpenAI API Key ì…ë ¥")

    st.divider()
    st.header("ğŸ›ï¸ ì¶”ì²œ í’ˆì§ˆ(ê°ê´€ì„±/ì¥ë¥´ ì í•©ì„±) í•„í„°")
    min_vote_count = st.slider("ìµœì†Œ íˆ¬í‘œìˆ˜(vote_count)", 0, 5000, 300, 50)
    min_vote_avg = st.slider("ìµœì†Œ í‰ì (vote_average)", 0.0, 9.0, 6.5, 0.1)
    require_poster = st.toggle("í¬ìŠ¤í„° ìˆëŠ” ì‘í’ˆë§Œ", value=True)
    require_overview = st.toggle("ì¤„ê±°ë¦¬ ìˆëŠ” ì‘í’ˆë§Œ", value=True)

    strict_genre = st.toggle("ì¥ë¥´ ì—„ê²© ëª¨ë“œ(ì¶”ì²œ ë¦¬ìŠ¤íŠ¸)", value=True)
    st.caption(
        "- ì¼œì§: í›„ë³´ ì˜í™”ì˜ **ìƒì„¸ ì¥ë¥´ì— ëª©í‘œ ì¥ë¥´ê°€ ì‹¤ì œ í¬í•¨**ëœ ê²ƒë§Œ í†µê³¼\n"
        "- í˜¼í•© ì¥ë¥´(ë™ì /ê·¼ì ‘)ì¼ ë•Œë„ ë” ì—„ê²©í•˜ê²Œ ê±¸ëŸ¬ìš”"
    )

    st.divider()
    st.header("ğŸ§­ ì •ë ¬/ê°€ì¤‘ì¹˜")
    sort_label = st.selectbox("ì •ë ¬ ì˜µì…˜", list(SORT_OPTIONS.keys()), index=0)

    st.subheader("ê°œì¸ ì·¨í–¥ ê°€ì¤‘ì¹˜(ìŠ¬ë¼ì´ë”)")
    st.caption("â€˜ê°œì¸ ì·¨í–¥ ê°€ì¤‘ì¹˜(ë¡œì»¬ ì ìˆ˜)â€™ ì •ë ¬ì—ì„œë§Œ ì ìš©ë¼ìš”.")
    w_recency = st.slider("ìµœì‹ ì„± ê°€ì¤‘ì¹˜", 0, 100, 30, 5)
    w_rating = st.slider("í‰ì  ê°€ì¤‘ì¹˜", 0, 100, 50, 5)
    w_votes = st.slider("íˆ¬í‘œìˆ˜ ê°€ì¤‘ì¹˜", 0, 100, 20, 5)

    st.divider()
    st.header("ğŸ¤– ìµœì¢… 1í¸ AI í”½")
    llm_model = st.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")

    st.divider()
    st.header("ğŸš« ì œì™¸ ëª©ë¡")
    st.caption("ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì œì™¸í•œ ì˜í™”ë“¤ì€ ë‹¤ìŒ ì¶”ì²œì—ì„œ ë‚˜ì˜¤ì§€ ì•Šì•„ìš”.")
    if st.button("ğŸ§¹ ì œì™¸ ëª©ë¡ ì´ˆê¸°í™”"):
        st.session_state["excluded_movie_ids"] = set()
        st.success("ì œì™¸ ëª©ë¡ì„ ì´ˆê¸°í™”í–ˆì–´ìš”!")


# =========================
# ë¶„ì„/ìœ í‹¸ í•¨ìˆ˜
# =========================
def analyze_genre(selected_indices: List[int]) -> Tuple[str, List[int], Dict[str, int], Optional[str], Optional[str]]:
    counts = {k: 0 for k in CATEGORY_TO_GENRE_IDS.keys()}
    for idx in selected_indices:
        counts[INDEX_TO_CATEGORY[idx]] += 1

    ranked = sorted(counts.items(), key=lambda x: x[1], reverse=True)
    top_cat, top_score = ranked[0]
    second_cat, second_score = ranked[1]

    blended = None
    secondary = None

    if top_score == second_score or (top_score - second_score == 1):
        secondary = second_cat
        blended = f"{top_cat} + {second_cat}"
        genre_ids = list(set(CATEGORY_TO_GENRE_IDS[top_cat] + CATEGORY_TO_GENRE_IDS[second_cat]))
        return top_cat, genre_ids, counts, blended, secondary

    return top_cat, CATEGORY_TO_GENRE_IDS[top_cat], counts, None, None


def with_genres_or(genre_ids: List[int]) -> str:
    return "|".join(str(g) for g in genre_ids)


@st.cache_data(show_spinner=False, ttl=60 * 60 * 24)
def tmdb_get_configuration(api_key: str) -> Dict:
    r = requests.get(f"{TMDB_BASE}/configuration", params={"api_key": api_key}, timeout=15)
    r.raise_for_status()
    return r.json()


def pick_poster_size(cfg: Dict, prefer: str = "w500") -> str:
    sizes = (cfg.get("images") or {}).get("poster_sizes") or []
    if prefer in sizes:
        return prefer
    for candidate in ["w500", "w342", "w780", "original"]:
        if candidate in sizes:
            return candidate
    return "w500"


def build_poster_url(cfg: Dict, poster_path: Optional[str]) -> Optional[str]:
    if not poster_path:
        return None
    images = cfg.get("images") or {}
    base = images.get("secure_base_url") or images.get("base_url")
    if not base:
        return "https://image.tmdb.org/t/p/w500" + poster_path
    size = pick_poster_size(cfg, "w500")
    return f"{base}{size}{poster_path}"


@st.cache_data(show_spinner=False, ttl=300)
def discover_movies(
    api_key: str,
    with_genres: str,
    language: str = "ko-KR",
    sort_by: str = "popularity.desc",
    page: int = 1,
    n: int = 20,
) -> List[Dict]:
    params = {
        "api_key": api_key,
        "with_genres": with_genres,
        "language": language,
        "sort_by": sort_by,
        "include_adult": "false",
        "page": page,
    }
    r = requests.get(f"{TMDB_BASE}/discover/movie", params=params, timeout=15)
    r.raise_for_status()
    data = r.json()
    return (data.get("results") or [])[:n]


@st.cache_data(show_spinner=False, ttl=60 * 60)
def movie_details(api_key: str, movie_id: int, language: str = "ko-KR") -> Dict:
    r = requests.get(
        f"{TMDB_BASE}/movie/{movie_id}",
        params={"api_key": api_key, "language": language},
        timeout=15,
    )
    r.raise_for_status()
    return r.json()


def parse_date_yyyymmdd(s: str) -> Optional[datetime]:
    try:
        return datetime.strptime(s, "%Y-%m-%d")
    except Exception:
        return None


def compute_personal_score(
    movie: Dict,
    primary_category: str,
    chosen_counts: Dict[str, int],
    w_recency: float,
    w_rating: float,
    w_votes: float,
) -> float:
    rating = float(movie.get("vote_average") or 0.0)
    vote_count = float(movie.get("vote_count") or 0.0)
    release_date = parse_date_yyyymmdd(movie.get("release_date") or "")

    pref_weight = float(chosen_counts.get(primary_category, 0)) / 5.0

    recency = 0.0
    if release_date:
        days = max((datetime.now() - release_date).days, 0)
        recency = max(0.0, 1.0 - (days / 365.0))

    vote_component = 0.0
    if vote_count > 0:
        vote_component = min(1.0, (vote_count ** 0.5) / 200.0)

    rating_component = max(0.0, min(1.0, rating / 10.0))

    wr = w_recency / 100.0
    wra = w_rating / 100.0
    wv = w_votes / 100.0

    score = (pref_weight * 1.5) + (recency * wr) + (rating_component * wra) + (vote_component * wv)
    return score


def passes_quality_filters(
    movie: Dict,
    cfg: Dict,
    min_vote_count: int,
    min_vote_avg: float,
    require_poster: bool,
    require_overview: bool,
) -> bool:
    if float(movie.get("vote_average") or 0.0) < float(min_vote_avg):
        return False
    if int(movie.get("vote_count") or 0) < int(min_vote_count):
        return False
    if require_overview and not (movie.get("overview") or "").strip():
        return False
    if require_poster and not movie.get("poster_path"):
        return False
    if require_poster and not build_poster_url(cfg, movie.get("poster_path")):
        return False
    return True


def movie_has_required_genres(detail: Dict, required_any: List[int], required_all: Optional[List[int]] = None) -> bool:
    genres = detail.get("genres") or []
    ids = {g.get("id") for g in genres if isinstance(g, dict)}
    if required_all:
        return all(g in ids for g in required_all)
    return any(g in ids for g in required_any)


def build_candidates_strict(
    api_key: str,
    cfg: Dict,
    with_genres: str,
    sort_by: str,
    primary_required_ids: List[int],
    secondary_required_ids: Optional[List[int]],
    strict_genre: bool,
    min_vote_count: int,
    min_vote_avg: float,
    require_poster: bool,
    require_overview: bool,
    excluded_ids: set,
    fetch_pages: int = 4,
    per_page_take: int = 20,
    target_n: int = 10,
) -> List[Dict]:
    picked: List[Dict] = []
    seen = set()

    required_all = None
    if strict_genre and secondary_required_ids:
        required_all = [primary_required_ids[0], secondary_required_ids[0]]

    for page in range(1, fetch_pages + 1):
        raw = discover_movies(api_key, with_genres, sort_by=sort_by, page=page, n=per_page_take)
        for m in raw:
            mid = int(m.get("id") or 0)
            if not mid or mid in seen or mid in excluded_ids:
                continue
            seen.add(mid)

            if not passes_quality_filters(m, cfg, min_vote_count, min_vote_avg, require_poster, require_overview):
                continue

            try:
                d = movie_details(api_key, mid, language="ko-KR")
            except Exception:
                continue

            required_any = primary_required_ids
            ok = movie_has_required_genres(d, required_any=required_any, required_all=required_all)
            if not ok:
                continue

            merged = {**m, **d}
            if not passes_quality_filters(merged, cfg, min_vote_count, min_vote_avg, require_poster, require_overview):
                continue

            picked.append(merged)
            if len(picked) >= target_n:
                return picked

    return picked


def why_recommended_text(category: str) -> str:
    if category == "ë¡œë§¨ìŠ¤/ë“œë¼ë§ˆ":
        return "TMDB ë¡œë§¨ìŠ¤(10749) ê¸°ì¤€ìœ¼ë¡œ **ë¡œë§¨ìŠ¤ ì¥ë¥´ê°€ ì‹¤ì œ í¬í•¨ëœ ì‘í’ˆë§Œ** ì—„ê²©íˆ ê³¨ëì–´ìš” ğŸ’•"
    if category == "ì•¡ì…˜/ì–´ë“œë²¤ì²˜":
        return "ì•¡ì…˜(28) ì¥ë¥´ê°€ ì‹¤ì œ í¬í•¨ëœ ì‘í’ˆë§Œ ì—„ê²©íˆ ê³¨ëì–´ìš” ğŸ’¥"
    if category == "SF/íŒíƒ€ì§€":
        return "SF(878)/íŒíƒ€ì§€(14) ì¥ë¥´ê°€ ì‹¤ì œ í¬í•¨ëœ ì‘í’ˆë§Œ ì—„ê²©íˆ ê³¨ëì–´ìš” ğŸš€"
    return "ì½”ë¯¸ë””(35) ì¥ë¥´ê°€ ì‹¤ì œ í¬í•¨ëœ ì‘í’ˆë§Œ ì—„ê²©íˆ ê³¨ëì–´ìš” ğŸ˜‚"


# =========================
# LLM ìµœì¢… 1í¸ í”½
# =========================
def safe_json_extract(text: str) -> Optional[dict]:
    if not text:
        return None
    m = re.search(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass
    m = re.search(r"(\{.*\})", text, re.DOTALL)
    if m:
        blob = m.group(1)
        try:
            return json.loads(blob)
        except Exception:
            try:
                blob2 = re.sub(r",\s*}", "}", blob)
                blob2 = re.sub(r",\s*]", "]", blob2)
                return json.loads(blob2)
            except Exception:
                return None
    return None


def llm_pick_one_movie(
    openai_api_key: str,
    model: str,
    user_profile: Dict,
    candidates: List[Dict],
) -> Tuple[Optional[int], str]:
    client = OpenAI(api_key=openai_api_key)

    compact = []
    for c in candidates:
        compact.append(
            {
                "id": c.get("id"),
                "title": c.get("title") or c.get("name"),
                "vote_average": c.get("vote_average"),
                "vote_count": c.get("vote_count"),
                "release_date": c.get("release_date"),
                "genres": c.get("genres", []),
                "overview": (c.get("overview") or "")[:650],
            }
        )

    system = (
        "ë„ˆëŠ” ëŒ€í•™ìƒ ì‚¬ìš©ìì˜ ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í›„ë³´ ì˜í™” ì¤‘ 'ê°€ì¥ ì¢‹ì•„í•  í™•ë¥ 'ì´ ë†’ì€ ì˜í™” 1í¸ì„ ê³ ë¥´ëŠ” ì¶”ì²œ ì „ë¬¸ê°€ì•¼. "
        "ì‚¬ìš©ìì˜ ì„±í–¥(ì„ íƒí•œ ë‹µë³€ì˜ ë¶„ìœ„ê¸°/ì¥ë¥´ ì„ í˜¸)ì„ ìµœìš°ì„ ìœ¼ë¡œ, "
        "ê·¸ ë‹¤ìŒìœ¼ë¡œëŠ” ê°ê´€ ì§€í‘œ(í‰ì /íˆ¬í‘œìˆ˜)ì™€ ì ‘ê·¼ì„±(ë¶€ë‹´ ì—†ëŠ” ì„ íƒ)ì„ ê³ ë ¤í•´."
    )

    payload = {
        "task": "pick_exactly_one",
        "user_profile": user_profile,
        "candidates": compact,
        "output_schema": {
            "movie_id": "number (must be one of candidates.id)",
            "reason": "string (Korean, 2~4 sentences, specific)",
            "why_youll_like": ["string", "string", "string"],
        },
        "rules": [
            "ë°˜ë“œì‹œ í›„ë³´ ì¤‘ ì •í™•íˆ 1ê°œì˜ idë§Œ ì„ íƒí•´.",
            "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ. ë‹¤ë¥¸ í…ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡/ì„¤ëª… ê¸ˆì§€.",
            "í•œêµ­ì–´ë¡œ ì‘ì„±.",
        ],
    }

    resp = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": system},
            {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
        ],
    )

    text_out = ""
    try:
        text_out = resp.output_text
    except Exception:
        try:
            for item in resp.output:
                if item.type == "message":
                    for c in item.content:
                        if c.type == "output_text":
                            text_out += c.text
        except Exception:
            text_out = ""

    data = safe_json_extract(text_out)
    if not data:
        return None, "ğŸ¤– ìµœì¢… ì¶”ì²œì„ ë§Œë“¤ì§€ ëª»í–ˆì–´ìš”. (LLM ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨)"

    movie_id = data.get("movie_id")
    reason = data.get("reason", "")
    bullets = data.get("why_youll_like", [])
    if not isinstance(bullets, list):
        bullets = []

    md = "### ğŸ¤– AI ìµœì¢… ì¶”ì²œ ì´ìœ \n"
    if reason:
        md += f"- {reason}\n"
    if bullets:
        md += "\n**âœ… ë‹¹ì‹ ì´ ì¢‹ì•„í•  í¬ì¸íŠ¸**\n"
        for b in bullets[:3]:
            md += f"- {b}\n"

    try:
        return int(movie_id), md
    except Exception:
        return None, "ğŸ¤– ìµœì¢… ì¶”ì²œì„ ë§Œë“¤ì§€ ëª»í–ˆì–´ìš”. (movie_id ì˜¤ë¥˜)"


# =========================
# ì¶”ì²œ ì‹¤í–‰ í•¨ìˆ˜ (ë²„íŠ¼ ì¬ì‚¬ìš©ìš©)
# =========================
def run_recommendation(reuse_context: Optional[dict] = None) -> None:
    """
    reuse_contextê°€ ìˆìœ¼ë©´(=ì œì™¸ í›„ ë‹¤ì‹œ ì¶”ì²œ) ê¸°ì¡´ ë¶„ì„/ë‹µë³€ì„ ì¬ì‚¬ìš©
    """
    if not tmdb_key or not openai_key:
        st.error("TMDB/OpenAI API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì£¼ì„¸ìš”! ğŸ”‘")
        return

    if reuse_context:
        context = reuse_context
        category = context["category"]
        genre_ids = context["genre_ids"]
        counts = context["counts"]
        blended = context["blended"]
        secondary_category = context["secondary_category"]
        answers = context["answers"]
        sort_label_local = context["sort_label"]
        is_personal = context["is_personal"]
        sort_by = context["sort_by"]
        with_genres = context["with_genres"]
    else:
        # ìƒˆë¡œ ë¶„ì„
        category, genre_ids, counts, blended, secondary_category = analyze_genre(selected_indices)
        answers = {"q1": q1, "q2": q2, "q3": q3, "q4": q4, "q5": q5}
        sort_by, is_personal = SORT_OPTIONS[sort_label]
        with_genres = with_genres_or(genre_ids)
        sort_label_local = sort_label

        context = {
            "category": category,
            "genre_ids": genre_ids,
            "counts": counts,
            "blended": blended,
            "secondary_category": secondary_category,
            "answers": answers,
            "sort_label": sort_label_local,
            "is_personal": is_personal,
            "sort_by": sort_by,
            "with_genres": with_genres,
        }
        st.session_state["last_reco_context"] = context

    badge = CATEGORY_BADGE[category]
    st.markdown(f"## ğŸ¯ ë‹¹ì‹ ì—ê²Œ ë”±ì¸ ì¥ë¥´ëŠ”: **{badge} {category}**!")
    st.info(REASON_BY_CATEGORY[category])
    st.caption(f"ğŸ“Š ì„ íƒ ë¶„í¬: {counts}")

    # configuration
    with st.spinner("ğŸ–¼ï¸ í¬ìŠ¤í„° ì„¤ì •ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        try:
            cfg = tmdb_get_configuration(tmdb_key)
        except requests.RequestException:
            cfg = {"images": {"secure_base_url": "https://image.tmdb.org/t/p/", "poster_sizes": ["w500"]}}
    st.session_state["last_cfg"] = cfg

    # í›„ë³´ í•„í„°ë§
    primary_required = CATEGORY_TO_GENRE_IDS[category]
    secondary_required = CATEGORY_TO_GENRE_IDS.get(secondary_category) if secondary_category else None

    discover_sort_for_fetch = "popularity.desc" if is_personal else (sort_by or "popularity.desc")

    with st.spinner("ğŸ¬ TMDBì—ì„œ í›„ë³´ë¥¼ ëª¨ìœ¼ê³ , ì¥ë¥´/ê°ê´€ í•„í„°ë¡œ ì—„ê²© ì„ ë³„ ì¤‘..."):
        filtered = build_candidates_strict(
            api_key=tmdb_key,
            cfg=cfg,
            with_genres=with_genres,
            sort_by=discover_sort_for_fetch,
            primary_required_ids=primary_required,
            secondary_required_ids=secondary_required,
            strict_genre=strict_genre,
            min_vote_count=min_vote_count,
            min_vote_avg=min_vote_avg,
            require_poster=require_poster,
            require_overview=require_overview,
            excluded_ids=st.session_state["excluded_movie_ids"],
            fetch_pages=5,
            per_page_take=20,
            target_n=20 if is_personal else 8,
        )

    if not filtered:
        st.warning(
            "ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì˜í™”ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš” ğŸ˜¢\n\n"
            "ğŸ‘‰ í•´ê²° íŒ: ìµœì†Œ í‰ì /ìµœì†Œ íˆ¬í‘œìˆ˜ë¥¼ ë‚®ì¶”ê±°ë‚˜, í¬ìŠ¤í„°/ì¤„ê±°ë¦¬ í•„ìˆ˜ ì˜µì…˜ì„ êº¼ë³´ì„¸ìš”.\n"
            "ë˜ëŠ” ì œì™¸ ëª©ë¡ì´ ë„ˆë¬´ ë§ë‹¤ë©´ ì´ˆê¸°í™”í•´ë³´ì„¸ìš”."
        )
        return

    # ìµœì¢… í›„ë³´ 5ê°œ ê²°ì •
    if is_personal:
        scored = []
        for m in filtered:
            s = compute_personal_score(m, category, counts, w_recency, w_rating, w_votes)
            scored.append((s, m))
        scored.sort(key=lambda x: x[0], reverse=True)
        movies = [m for _, m in scored[:5]]
    else:
        movies = filtered[:5]

    st.markdown(
        ("### ğŸ¿ ì¶”ì²œ ì˜í™” TOP 5 (ì¥ë¥´/ê°ê´€ í•„í„° ì ìš©)" + (f" Â· ì·¨í–¥ ë¯¹ìŠ¤: {blended}" if blended else "") + f" Â· ì •ë ¬: {sort_label_local}")
    )
    st.caption(
        f"ì ìš© í•„í„°: í‰ì  â‰¥ {min_vote_avg}, íˆ¬í‘œìˆ˜ â‰¥ {min_vote_count}"
        + (" Â· í¬ìŠ¤í„°í•„ìˆ˜" if require_poster else "")
        + (" Â· ì¤„ê±°ë¦¬í•„ìˆ˜" if require_overview else "")
        + (" Â· ì¥ë¥´ì—„ê²©" if strict_genre else "")
        + (f" Â· ì œì™¸ {len(st.session_state['excluded_movie_ids'])}ê°œ" if st.session_state["excluded_movie_ids"] else "")
    )

    # LLM í›„ë³´ ì¤€ë¹„
    llm_candidates = []
    for m in movies:
        genres = m.get("genres") or []
        genre_names = [g.get("name") for g in genres if isinstance(g, dict) and g.get("name")]
        llm_candidates.append(
            {
                "id": int(m.get("id")),
                "title": m.get("title") or "ì œëª© ì—†ìŒ",
                "vote_average": float(m.get("vote_average") or 0.0),
                "vote_count": int(m.get("vote_count") or 0),
                "release_date": m.get("release_date") or "",
                "overview": (m.get("overview") or "").strip(),
                "genres": genre_names,
                "poster_path": m.get("poster_path"),
            }
        )
    st.session_state["last_llm_candidates"] = llm_candidates

    # LLM ìµœì¢… í”½
    user_profile = {
        "primary_category": category,
        "category_counts": counts,
        "selected_choices": answers,
        "sorting_mode": sort_label_local,
        "personal_weights": {"recency": w_recency, "rating": w_rating, "votes": w_votes},
        "quality_filters": {
            "min_vote_average": min_vote_avg,
            "min_vote_count": min_vote_count,
            "strict_genre": strict_genre,
            "require_poster": require_poster,
            "require_overview": require_overview,
        },
        "excluded_movie_ids": sorted(list(st.session_state["excluded_movie_ids"]))[:50],
        "note": "ëŒ€í•™ìƒ ê¸°ì¤€ìœ¼ë¡œ, ë¶€ë‹´ ì—†ì´ ì¬ë¯¸/ë§Œì¡±ë„ê°€ ë†’ì„ 1í¸ì„ ê³¨ë¼ì¤˜.",
    }

    with st.spinner("ğŸ¤– AIê°€ í›„ë³´ 5ê°œ ì¤‘ â€˜ì§„ì§œ ì·¨í–¥ì €ê²©â€™ 1í¸ì„ ê³ ë¥´ëŠ” ì¤‘..."):
        picked_id, picked_md = llm_pick_one_movie(openai_key, llm_model, user_profile, llm_candidates)

    st.session_state["last_picked_id"] = picked_id
    st.session_state["last_picked_md"] = picked_md

    # ìµœì¢… ì¶”ì²œ í‘œì‹œ
    if picked_id:
        picked = next((x for x in llm_candidates if x["id"] == picked_id), None)
        if picked:
            st.markdown("## â­ ìµœì¢… ì¶”ì²œ 1í¸")
            poster = build_poster_url(cfg, picked.get("poster_path"))
            left, right = st.columns([1, 2], gap="large")
            with left:
                if poster:
                    st.image(poster, use_container_width=True)
                else:
                    st.write("ğŸ–¼ï¸ í¬ìŠ¤í„° ì—†ìŒ")
            with right:
                st.markdown(f"### ğŸ¬ {picked['title']}")
                st.markdown(f"â­ í‰ì : **{picked['vote_average']:.1f}** / 10")
                st.markdown(f"ğŸ—³ï¸ íˆ¬í‘œìˆ˜: **{picked['vote_count']}**")
                rd = picked.get("release_date") or "ì •ë³´ ì—†ìŒ"
                st.markdown(f"ğŸ—“ï¸ ê°œë´‰ì¼: {rd}")
                if picked.get("genres"):
                    st.markdown(f"ğŸ·ï¸ ì¥ë¥´: {', '.join(picked['genres'])}")
                st.markdown(picked_md)

                with st.expander("ğŸ“ ì¤„ê±°ë¦¬ ë³´ê¸°"):
                    st.write(picked.get("overview") or "ì¤„ê±°ë¦¬ ì •ë³´ê°€ ì—†ì–´ìš”.")

            st.divider()

    # í›„ë³´ 5ê°œ ì¹´ë“œ + ì œì™¸ ì²´í¬
    st.markdown("### ğŸ§© ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ TOP 5")
    cols = st.columns(3, gap="large")

    for i, c in enumerate(llm_candidates):
        col = cols[i % 3]
        title = c.get("title") or "ì œëª© ì—†ìŒ"
        rating = float(c.get("vote_average") or 0.0)
        poster = build_poster_url(cfg, c.get("poster_path"))
        is_picked = (picked_id is not None and c["id"] == picked_id)

        with col:
            with st.container(border=True):
                if poster:
                    st.image(poster, use_container_width=True)
                else:
                    st.write("ğŸ–¼ï¸ í¬ìŠ¤í„° ì—†ìŒ")

                st.markdown(f"**{title}**")
                st.caption(
                    f"â­ {rating:.1f} / 10 Â· ğŸ—³ï¸ {c.get('vote_count', 0)}"
                    + (" Â· âœ… ìµœì¢… í”½" if is_picked else "")
                )

                # âœ… ì œì™¸ ì²´í¬ë°•ìŠ¤(í›„ë‹¨ ë²„íŠ¼ìœ¼ë¡œ ì œì™¸ í™•ì •)
                chk_key = f"exclude_chk_{c['id']}"
                default_checked = (c["id"] in st.session_state["excluded_movie_ids"])
                st.checkbox("ğŸš« ì´ ì˜í™”ëŠ” ì œì™¸", key=chk_key, value=default_checked)

                with st.expander("ğŸ“Œ ìƒì„¸ ì •ë³´ ë³´ê¸°"):
                    st.markdown(f"ğŸ’¡ **ì¶”ì²œ ê¸°ì¤€**: {why_recommended_text(category)}")
                    if c.get("release_date"):
                        st.markdown(f"ğŸ—“ï¸ **ê°œë´‰ì¼**: {c['release_date']}")
                    if c.get("genres"):
                        st.markdown(f"ğŸ·ï¸ **ì¥ë¥´**: {', '.join(c['genres'])}")
                    st.markdown("ğŸ“ **ì¤„ê±°ë¦¬**")
                    st.write(c.get("overview") or "ì¤„ê±°ë¦¬ ì •ë³´ê°€ ì—†ì–´ìš”.")


# =========================
# ì§ˆë¬¸ 5ê°œ UI
# =========================
st.subheader("ğŸ“ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”")
q1_options = [
    "ğŸ’• ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒê³¼ ì¹´í˜ì—ì„œ ì˜¤ë˜ ì–˜ê¸°í•˜ê¸°",
    "ğŸ’¥ ì¹œêµ¬ë“¤ì´ë‘ ë°”ë¡œ ì—¬í–‰ì´ë‚˜ ì•¡í‹°ë¹„í‹° ë– ë‚˜ê¸°",
    "ğŸš€ ê²Œì„Â·ì˜í™” ëª°ì•„ë³´ë©´ì„œ ë‹¤ë¥¸ ì„¸ê³„ë¡œ ë„í”¼í•˜ê¸°",
    "ğŸ˜‚ ì›ƒê¸´ ì˜ìƒ ë³´ë©´ì„œ ì•„ë¬´ ìƒê° ì—†ì´ ì‰¬ê¸°",
]
q2_options = [
    "ğŸ’• ê°ì •ì´ì… ë˜ëŠ” ì˜í™”ë‚˜ ë“œë¼ë§ˆ ë³´ë©° ìš¸ê¸°",
    "ğŸ’¥ ìš´ë™í•˜ê±°ë‚˜ ëª¸ì„ ë§ì´ ì›€ì§ì´ê¸°",
    "ğŸš€ ìƒìƒë ¥ ìê·¹í•˜ëŠ” ì½˜í…ì¸ ì— ë¹ ì ¸ë“¤ê¸°",
    "ğŸ˜‚ ì¹œêµ¬ë‘ ìˆ˜ë‹¤ ë–¨ê±°ë‚˜ ì›ƒê¸´ ê±° ì°¾ê¸°",
]
q3_options = [
    "ğŸ’• í˜„ì‹¤ ê³µê° 100% ì¸ê°„ê´€ê³„ ì´ì•¼ê¸°",
    "ğŸ’¥ ìŠ¤ì¼€ì¼ í¬ê³  ë°•ì§„ê° ë„˜ì¹˜ëŠ” ì˜í™”",
    "ğŸš€ ì„¸ê³„ê´€ì´ íƒ„íƒ„í•œ íŒíƒ€ì§€ë‚˜ ë¯¸ë˜ ì´ì•¼ê¸°",
    "ğŸ˜‚ ê°€ë³ê²Œ ì›ƒìœ¼ë©´ì„œ ë³¼ ìˆ˜ ìˆëŠ” ì˜í™”",
]
q4_options = [
    "ğŸ’• ê°ì •ì´ ì„¬ì„¸í•˜ê³  ê´€ê³„ê°€ ì¤‘ìš”í•œ ì¸ë¬¼",
    "ğŸ’¥ ìœ„ê¸°ë§ˆë‹¤ í™œì•½í•˜ëŠ” íˆì–´ë¡œ",
    "ğŸš€ íŠ¹ë³„í•œ ëŠ¥ë ¥ì„ ê°€ì§„ ì¡´ì¬",
    "ğŸ˜‚ ì£¼ë³€ ë¶„ìœ„ê¸°ë¥¼ ì‚´ë¦¬ëŠ” ì›ƒê¸´ ìºë¦­í„°",
]
q5_options = [
    "ğŸ’• ê³µê° ì˜ í•´ì£¼ê³  ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì–´ì¤€ë‹¤",
    "ğŸ’¥ ì¶”ì§„ë ¥ ìˆê³  ê°™ì´ ìˆìœ¼ë©´ ë“ ë“ í•˜ë‹¤",
    "ğŸš€ ë…íŠ¹í•˜ê³  ìƒê°ì´ ê¹Šë‹¤",
    "ğŸ˜‚ ê°™ì´ ìˆìœ¼ë©´ ì›ƒì„ ì¼ì´ ë§ë‹¤",
]

q1 = st.radio("1) ì‹œí—˜ ëë‚˜ê³  ê°€ì¥ í•˜ê³  ì‹¶ì€ ê±´?", q1_options, index=0)
q2 = st.radio("2) ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ìŒ“ì˜€ì„ ë•Œ ë„ˆì˜ ë°˜ì‘ì€?", q2_options, index=0)
q3 = st.radio("3) ì£¼ë§ì— ì˜í™” í•œ í¸ì„ ë³¸ë‹¤ë©´?", q3_options, index=0)
q4 = st.radio("4) ì˜í™” ì† ì£¼ì¸ê³µì´ ëœë‹¤ë©´ ë” ëŒë¦¬ëŠ” ì—­í• ì€?", q4_options, index=0)
q5 = st.radio("5) ì¹œêµ¬ë“¤ì´ ë§í•˜ëŠ” ë‚˜ì˜ ì´ë¯¸ì§€ì™€ ê°€ì¥ ê°€ê¹Œìš´ ê±´?", q5_options, index=0)

selected_indices = [
    q1_options.index(q1),
    q2_options.index(q2),
    q3_options.index(q3),
    q4_options.index(q4),
    q5_options.index(q5),
]

st.divider()

# =========================
# (1) ì²« ì¶”ì²œ ë²„íŠ¼
# =========================
if st.button("ğŸ”® ê²°ê³¼ ë³´ê¸°"):
    run_recommendation(reuse_context=None)

# =========================
# (2) ì¶”ì²œ í›„ í•˜ë‹¨ ë²„íŠ¼: ì œì™¸ ë°˜ì˜ + ë‹¤ì‹œ ì¶”ì²œ
# =========================
# last_llm_candidatesê°€ ìˆìœ¼ë©´(=ì¶”ì²œì„ í•œ ë²ˆì´ë¼ë„ í–ˆìœ¼ë©´) ë²„íŠ¼ ë…¸ì¶œ
if st.session_state.get("last_llm_candidates"):
    st.divider()
    st.subheader("ğŸ” ë§ˆìŒì— ì•ˆ ë“œëŠ” ì˜í™”ê°€ ìˆë‚˜ìš”?")
    st.write("ìœ„ ë¦¬ìŠ¤íŠ¸ì—ì„œ `ğŸš« ì´ ì˜í™”ëŠ” ì œì™¸`ë¥¼ ì²´í¬í•œ ë’¤ ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, í•´ë‹¹ ì˜í™”ë“¤ì€ ì œì™¸í•˜ê³  ë‹¤ì‹œ ì¶”ì²œí•´ìš”!")

    if st.button("ğŸš€ ì œì™¸ ë°˜ì˜í•´ì„œ ë‹¤ì‹œ ì¶”ì²œ"):
        # ì²´í¬ëœ í•­ëª©ì„ excluded_movie_idsì— ë°˜ì˜
        newly_excluded = set(st.session_state["excluded_movie_ids"])
        for c in st.session_state["last_llm_candidates"]:
            chk_key = f"exclude_chk_{c['id']}"
            if st.session_state.get(chk_key):
                newly_excluded.add(int(c["id"]))
        st.session_state["excluded_movie_ids"] = newly_excluded

        # ì¬ì¶”ì²œ ì‹¤í–‰(ê°™ì€ ë¶„ì„/ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ ì¬ì‚¬ìš©)
        ctx = st.session_state.get("last_reco_context")
        run_recommendation(reuse_context=ctx)
